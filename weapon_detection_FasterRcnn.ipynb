{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for extracting bounding boxes and loading dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_BBoxes(filename):\n",
    "   #find root of file\n",
    "    root = ET.parse(filename).getroot()\n",
    "    \n",
    "    boxes = list()\n",
    "    names = list()\n",
    "    # get bounding boxes and names\n",
    "    for objct in root.findall(\".//object\"):\n",
    "        name = objct.find('name').text\n",
    "        xmin = int(objct.find('bndbox/xmin').text)\n",
    "        ymin = int(objct.find('bndbox/ymin').text)\n",
    "        xmax = int(objct.find('bndbox/xmax').text)\n",
    "        ymax = int(objct.find('bndbox/ymax').text)\n",
    "        names.append(name)\n",
    "        boxes.append([xmin,ymin,xmax,ymax])\n",
    "\n",
    "    return [boxes,names]\n",
    "    \n",
    "def load_dataset(path, deleteFiles = False):\n",
    "    files_xml = [f for f in glob.glob(str(path) + \"/*.xml\")] # comes in random order\n",
    "    \n",
    "    imgbbox = dict()\n",
    "    #print(len(files_xml))\n",
    "    for file in files_xml:  \n",
    "        \n",
    "        imgFilePath = file[:-3] + \"jpg\"\n",
    "        if os.path.exists(imgFilePath):  \n",
    "            lbl_bbox = extract_BBoxes(file)  # Gets the bbox information\n",
    "            \n",
    "            imgbbox.update({imgFilePath.replace(str(path)+\"/\",''): lbl_bbox})\n",
    "            \n",
    "        elif deleteFiles:\n",
    "            print(\"Found xml with no jpg\")\n",
    "            print(\"Deleting xml file: %s\" %file)\n",
    "            os.remove(file)\n",
    "            print(\"Deleted\")\n",
    "\n",
    "    return imgbbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images and making test/train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgbboxes = load_dataset('../Project2', deleteFiles=False)\n",
    "new_imgbbox = {}\n",
    "for img in imgbboxes:\n",
    "\n",
    "    if len(imgbboxes[img][1]) == 1:\n",
    "        new_imgbbox.update( {img: imgbboxes[img]})\n",
    "\n",
    "labels = [new_imgbbox[file][1] for file in new_imgbbox]\n",
    "\n",
    "path = '../Project2'\n",
    "\n",
    "imgList = []\n",
    "for file in new_imgbbox:\n",
    "    temp = cv2.imread(os.path.join(path,file))\n",
    "    if temp is not None:\n",
    "        imgList.append(temp)\n",
    "\n",
    "images = np.array(imgList)\n",
    "\n",
    "\n",
    "n_categories = 2\n",
    "split = 367\n",
    "\n",
    "x_train = images[:split]\n",
    "x_test = images[split:]\n",
    "\n",
    "y_train = labels[:split]\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i][0] == 'handgun':\n",
    "        y_train[i] = 1\n",
    "        \n",
    "    else:\n",
    "        y_train[i] = 2\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_train = keras.utils.to_categorical(y_train-1, n_categories)\n",
    "\n",
    "y_test = labels[split:]\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i][0] == 'handgun':\n",
    "        y_test[i] = 1\n",
    "        \n",
    "    else:\n",
    "        y_test[i] = 2\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "y_test = keras.utils.to_categorical(y_test-1, n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making model, training and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 [==============================] - 11s 897ms/step - loss: 1.4037 - accuracy: 0.6267 - val_loss: 0.7231 - val_accuracy: 0.6200\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 10s 864ms/step - loss: 0.6797 - accuracy: 0.6485 - val_loss: 0.7051 - val_accuracy: 0.6200\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 11s 945ms/step - loss: 0.6648 - accuracy: 0.6567 - val_loss: 0.7154 - val_accuracy: 0.6400\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 14s 1s/step - loss: 0.6685 - accuracy: 0.6485 - val_loss: 0.7018 - val_accuracy: 0.6200\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 11s 907ms/step - loss: 0.6524 - accuracy: 0.6567 - val_loss: 0.7069 - val_accuracy: 0.6300\n",
      "\n",
      "Accuracy:\t 0.6299999952316284 \n",
      "Loss:    \t 0.7069478034973145\n"
     ]
    }
   ],
   "source": [
    "n, y, x, d = x_train.shape\n",
    "inputShape = (y,x,d)\n",
    "n_iterations = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(12, 3, activation='relu', input_shape=inputShape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(12, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(12, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(10, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(8, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(4, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(2, 3, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(units = 2, activation='softmax'))\n",
    "\n",
    "# compiling model with cross entropy and accuracy\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# training model\n",
    "model.fit(x_train, y_train, epochs=n_iterations, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\nAccuracy:\\t\", accuracy, \"\\nLoss:    \\t\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
